# Introduction

Linear regression is a statistical method used to analyze the relationship between at least two variables: one dependent variable and at least one independent variable. This technique is closely tied to the correlation coefficient, which measures the strength and direction of a linear relationship between variables. In this document, we will explore how these concepts are connected.

Linear regression is typically applied for three main purposes:

- **Description:** To describe the relationship between the variables under analysis.
- **Control:** To predict how changes in the independent variables will affect the dependent variable.
- **Prediction:** To forecast the value of the dependent variable based on new observations of the independent variables.

## Examples

### Ad Spending

Imagine you are a newly hired data scientist at a mattress company. Your manager asks you to analyze the relationship between Google ad spending and mattress sales revenue.

To illustrate this scenario, I have simulated a dataset:
```
# Ad Spending Example

# Set Seed
set.seed(8272024)

# Data Simulation
x <- rnorm(n    = 100,
           mean = 70,
           sd   = 30)
y <- 1000 + 5 * x + rnorm(n = 100, mean = 0, sd = 100)

# Creates the Data Frame
datAd <- data.frame(cbind(y,x))

# Names the Variables
colnames(datAd) <- c("Revenue", "Ad Spending")

# Saves to csv
write.csv(x    = datAd[, c(1, 2)],
          file = "Ad spending Data.csv", row.names = FALSE)
```

You can load the dataset as follows:

```
dat <- read.csv(file = "Ad spending Data.csv")
```

To visualize the data:

```{r}
plot(x = dat$Ad.Spending,
     y = dat$Revenue,
     xlab = "Ad Spending ($)",
     ylab = "Revenue ($)")
```

Next, you can perform a linear regression analysis:

```{r}
outReg <- lm(Revenue ~ Ad.Spending, data = dat)
```

The most important results from the regression analysis can be summarized as follows:

```{r}
summary(outReg)
```

For now, letâ€™s focus on the **estimate** for the intercept and the Ad.Spending coefficient. The **intercept** indicates the expected revenue when ad spending is zero. Based on your analysis, you observe that even without an ad campaign, mattress sales generate $r outReg$coefficients[1]. The **coefficient** for Ad.Spending shows that each dollar spent on ads increases revenue by $r outReg$coefficients[2].

To visualize the regression line:

```{r}
plot(x = dat$Ad.Spending,
     y = dat$Revenue,
     xlab = "Ad Spending ($)",
     ylab = "Revenue ($)")
abline(a   = outReg$coefficients[1],
       b   = outReg$coefficients[2],
       col = 'red',
       lwd = 2)
```

The red regression line represents the "best fit" for these variables. In this context, "best fit" means the line that minimizes the sum of the squared distances from each point to the line. For comparison, here are examples of other lines that do not fit as well:

Different **slope** (coefficient for the Ad.Spending variable):

```{r}
plot(x = dat$Ad.Spending,
     y = dat$Revenue,
     xlab = "Ad Spending ($)",
     ylab = "Revenue ($)")
abline(a   = outReg$coefficients[1],
       b   = outReg$coefficients[2],
       col = 'red',
       lwd = 2)
abline(a   = outReg$coefficients[1],
       b   = 6,
       col = 'blue',
       lwd = 2)
```

Different **intercept**:

```{r}
plot(x = dat$Ad.Spending,
     y = dat$Revenue,
     xlab = "Ad Spending ($)",
     ylab = "Revenue ($)")
abline(a   = outReg$coefficients[1],
       b   = outReg$coefficients[2],
       col = 'red',
       lwd = 2)
abline(a   = 1100,
       b   = outReg$coefficients[2],
       col = 'blue',
       lwd = 2)
```