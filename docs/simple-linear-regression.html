<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Simple Linear Regression | _main.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.40 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Simple Linear Regression | _main.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Simple Linear Regression | _main.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Stat 5385/6385</a></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prerequisites.html"><a href="prerequisites.html#general-math"><i class="fa fa-check"></i><b>2.1</b> General Math</a></li>
<li class="chapter" data-level="2.2" data-path="prerequisites.html"><a href="prerequisites.html#linear-algebra"><i class="fa fa-check"></i><b>2.2</b> Linear Algebra</a></li>
<li class="chapter" data-level="2.3" data-path="prerequisites.html"><a href="prerequisites.html#probability"><i class="fa fa-check"></i><b>2.3</b> Probability</a></li>
<li class="chapter" data-level="2.4" data-path="prerequisites.html"><a href="prerequisites.html#statistics"><i class="fa fa-check"></i><b>2.4</b> Statistics</a></li>
<li class="chapter" data-level="2.5" data-path="prerequisites.html"><a href="prerequisites.html#calculus"><i class="fa fa-check"></i><b>2.5</b> Calculus</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#examples"><i class="fa fa-check"></i><b>3.1</b> Examples</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction.html"><a href="introduction.html#ad-spending"><i class="fa fa-check"></i><b>3.1.1</b> Ad Spending</a></li>
<li class="chapter" data-level="3.1.2" data-path="introduction.html"><a href="introduction.html#winw-example"><i class="fa fa-check"></i><b>3.1.2</b> Wine and Life Expectancy</a></li>
<li class="chapter" data-level="3.1.3" data-path="introduction.html"><a href="introduction.html#burger-demand"><i class="fa fa-check"></i><b>3.1.3</b> Burger Demand</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model"><i class="fa fa-check"></i><b>4.1</b> Model</a></li>
<li class="chapter" data-level="4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#least-squares-estimation"><i class="fa fa-check"></i><b>4.2</b> Least Squares Estimation</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#other-estimated-quantites"><i class="fa fa-check"></i><b>4.2.1</b> Other estimated quantites</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#properties-of-the-estimates"><i class="fa fa-check"></i><b>4.3</b> Properties of the Estimates</a></li>
<li class="chapter" data-level="4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-and-standarizing-the-data"><i class="fa fa-check"></i><b>4.4</b> Centering and Standarizing the Data</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independent-variable-centered"><i class="fa fa-check"></i><b>4.4.1</b> Independent variable centered</a></li>
<li class="chapter" data-level="4.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#both-variables-centered"><i class="fa fa-check"></i><b>4.4.2</b> Both Variables centered</a></li>
<li class="chapter" data-level="4.4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#independent-and-dependent-variable-standardized"><i class="fa fa-check"></i><b>4.4.3</b> Independent and dependent variable standardized</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#coefficient-of-determination"><i class="fa fa-check"></i><b>4.5</b> Coefficient of Determination</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Simple Linear Regression<a href="simple-linear-regression.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Simple linear regression (<strong>SLR</strong>) is a linear regression model with a single explanatory variable. It focuses on the linear relationship between one independent variable and one dependent variable, making it the most basic form of linear regression analysis.</p>
<div id="model" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Model<a href="simple-linear-regression.html#model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The model for simple linear regression is as follows:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_i + e_i, \quad i\in\{1,\ldots,n\}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(y_i\)</span> represents the <span class="math inline">\(i\)</span>-th observation of the dependent variable.</li>
<li><span class="math inline">\(x_i\)</span> represents the <span class="math inline">\(i\)</span>-th observation of the independent variable.</li>
<li><span class="math inline">\(e_i\)</span> represents the <span class="math inline">\(i\)</span>-th observation of the error term.</li>
<li><span class="math inline">\(\beta_0\)</span> is the intercept of the linear model, or regression line.</li>
<li><span class="math inline">\(\beta_1\)</span> is the slope of the linear model, or regression line.</li>
<li><span class="math inline">\(n\)</span> is the number of observations for both variables.</li>
</ul>
<p>Note that we are not making any assumptions about the error terms.</p>
<p>In the case of the <a href="#wine-example">wine example</a>, we generated the data based on the following linear model:</p>
<p><span class="math display">\[y_i = 75 + 1.5 x_i + e_i \]</span></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="simple-linear-regression.html#cb16-1" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;Wine Data.csv&quot;</span>)</span>
<span id="cb16-2"><a href="simple-linear-regression.html#cb16-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> dat<span class="sc">$</span>Glasses,</span>
<span id="cb16-3"><a href="simple-linear-regression.html#cb16-3" tabindex="-1"></a>     <span class="at">y    =</span> dat<span class="sc">$</span>Years,</span>
<span id="cb16-4"><a href="simple-linear-regression.html#cb16-4" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Avg. Glasses of Wine per Week&quot;</span>,</span>
<span id="cb16-5"><a href="simple-linear-regression.html#cb16-5" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Life Expectancy (Years)&quot;</span>)</span>
<span id="cb16-6"><a href="simple-linear-regression.html#cb16-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> <span class="dv">75</span>,</span>
<span id="cb16-7"><a href="simple-linear-regression.html#cb16-7" tabindex="-1"></a>       <span class="at">b   =</span> <span class="fl">1.5</span>,</span>
<span id="cb16-8"><a href="simple-linear-regression.html#cb16-8" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb16-9"><a href="simple-linear-regression.html#cb16-9" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb16-10"><a href="simple-linear-regression.html#cb16-10" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v   =</span> <span class="dv">0</span>,</span>
<span id="cb16-11"><a href="simple-linear-regression.html#cb16-11" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb16-12"><a href="simple-linear-regression.html#cb16-12" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fl">0.25</span>, <span class="at">y =</span> <span class="dv">76</span>, <span class="fu">expression</span>(beta[<span class="dv">0</span>] <span class="sc">~</span> <span class="st">&quot;=75&quot;</span>))</span>
<span id="cb16-13"><a href="simple-linear-regression.html#cb16-13" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> <span class="fl">3.25</span>, <span class="at">y =</span> <span class="dv">79</span>, <span class="fu">expression</span>(beta[<span class="dv">1</span>] <span class="sc">~</span> <span class="st">&quot;=1.5&quot;</span>))</span>
<span id="cb16-14"><a href="simple-linear-regression.html#cb16-14" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>),</span>
<span id="cb16-15"><a href="simple-linear-regression.html#cb16-15" tabindex="-1"></a>         <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb16-16"><a href="simple-linear-regression.html#cb16-16" tabindex="-1"></a>         <span class="at">y0 =</span> <span class="fu">c</span>(<span class="dv">78</span>, <span class="dv">78</span>),</span>
<span id="cb16-17"><a href="simple-linear-regression.html#cb16-17" tabindex="-1"></a>         <span class="at">y1 =</span> <span class="fu">c</span>(<span class="dv">78</span>, <span class="fl">79.5</span>),</span>
<span id="cb16-18"><a href="simple-linear-regression.html#cb16-18" tabindex="-1"></a>         <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb16-19"><a href="simple-linear-regression.html#cb16-19" tabindex="-1"></a>         <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/slr-parts-1.png" width="672" /></p>
<p>In this case, the intercept <span class="math inline">\(\beta_0\)</span> is meaningful, as it represents the expected number of years a person would live if they didn’t drink wine at all. However, depending on the data, the intercept may or may not have a meaningful interpretation. The slope <span class="math inline">\(\beta_1\)</span> indicates that for each additional glass of wine consumed per week, our model predicts an increase of 1.5 years in life expectancy.</p>
<p>In practice, we rarely know the true regression line. Instead, it must be estimated from the data. The goal is to find the “best” line that fits the data, where “best” means the line that minimizes the sum of squared errors (SSE) between the observed values and the values predicted by the model.</p>
</div>
<div id="least-squares-estimation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Least Squares Estimation<a href="simple-linear-regression.html#least-squares-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As explained before, we want to minimize the SSE, we can create a function of
<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> with this sum as follows:</p>
<p><span class="math display">\[Q(\beta_0, \beta_1) = \sum_{i=1}^n (e_i(\beta_0, \beta_1))^2
= \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2  \]</span></p>
<p>and we can find the minimum of this function easily since it is a differentiable function. We can find the both components of the gradient and equal them to zero to find the critical points. We start with <span class="math inline">\(\beta_0\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial Q}{\partial \beta_0}
  &amp;= \frac{\partial}{\partial \beta_0} \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2 \\
  &amp;= \frac{\partial}{\partial \beta_0} \sum_{i=1}^n (y_i^2 + \beta_0^2 + \beta_1^2 x_i^2 - 2 \beta_0 y_i - 2 \beta_1 x_i y_i + 2 \beta_0 \beta_1 x_i) \\
  &amp;= \sum_{i = 1}^n (2 \beta_0 - 2 y_i + 2 \beta_1 x_i) \\
  &amp;= -2 \left( n \beta_0 - n \bar{y} + n\beta_1 \bar{x} \right)
\end{align*}\]</span></p>
<p>where we have adopted the notation: <span class="math inline">\(\bar{x} = \frac{1}{n}\sum_{i}^n x_i\)</span> and <span class="math inline">\(\bar{y} = \frac{1}{n}\sum_{i}^n y_i\)</span>.</p>
<p><span class="math display">\[\begin{align}
\frac{\partial Q}{\partial \beta_0} = 0
  &amp;\iff -2 \left( n \beta_0 - n \bar{y} + n\beta_1 \bar{x} \right) = 0 \notag \\
  &amp;\iff \beta_0 = \bar{y} - \beta_1 \bar{x} \tag{1}
\end{align}\]</span></p>
<p>And we can do a similar thing for <span class="math inline">\(\beta_1\)</span>:</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial Q}{\partial \beta_1}
  &amp;= \frac{\partial}{\partial \beta_0} \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2 \\
  &amp;= \sum_{i = 1}^n 2(y_i -\beta_0 - \beta_1 x_i)(-x_i) \\
  &amp;= -2\sum_{i = 1}^n y_i x_i + 2 \beta_0 \sum_{i = 1}^n x_i + 2 \beta_1 \sum_{i = 1}^n x_i^2 \\
  &amp;= -2\sum_{i = 1}^n y_i x_i + 2 n \beta_0 \bar{x} + 2 \beta_1 \sum_{i = 1}^n x_i^2
\end{align*}\]</span></p>
<p>then:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial Q}{\partial \beta_1} = 0
  &amp;\iff -2\sum_{i = 1}^n y_i x_i + 2 n \beta_0 \bar{x} + 2 \beta_1 \sum_{i = 1}^n x_i^2 = 0 \notag \\
  &amp;\iff \sum_{i = 1}^n y_i x_i = n \beta_0 \bar{x} + \beta_1  \sum_{i = 1}^n x_i^2 \tag{2}
\end{align}\]</span></p>
<p>Now, substituting (1) into (2) we have that</p>
<p><span class="math display">\[\begin{align*}
\sum_{i = 1}^n y_i x_i
  &amp;= n (\bar{y} - \beta_1 \bar{x}) \bar{x}  + \beta_1  \sum_{i = 1}^n x_i^2 \\
  &amp;= n \bar{y} \bar{x} - n \beta_1 \bar{x}^2 + \beta_1  \sum_{i = 1}^n x_i^2 \\
  &amp;= n \bar{y} \bar{x} + \beta_1 \left( \sum_{i = 1}^n x_i^2 - n \bar{x}^2 \right)
\end{align*}\]</span></p>
<p>Then,</p>
<p><span class="math display">\[ \beta_1 = \frac{\sum_{i = 1}^n y_i x_i - n \bar{y} \bar{x}}{\sum_{i = 1}^n x_i^2 - n \bar{x}^2} \]</span></p>
<p>so, the only critical point for <span class="math inline">\(Q(\beta_0,\beta_1)\)</span> is when:</p>
<p><span class="math display">\[ \hat{\beta}_1 = \frac{\sum_{i = 1}^n y_i x_i - n \bar{y} \bar{x}}{\sum_{i = 1}^n x_i^2 - n \bar{x}^2} \]</span>
<span class="math display">\[ \hat{\beta_0} = \bar{y} - \hat{\beta}_1 \bar{x}\]</span></p>
<p>where we use <span class="math inline">\(\hat{}\)</span>, to denote the specific critical point. It remains to see
if this is indeed a minimum. One can check the second order conditions.</p>
<p>Now, if we introduce the notation for sample variance and covariance:</p>
<p><span class="math display">\[ S^2_{xx} = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2 \]</span>
<span class="math display">\[ S_{xy}   = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) \]</span></p>
<p>and note the following:</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2
  &amp;= \frac{1}{n-1} \sum_{i=1}^n (x_i^2 - 2\bar{x}x_i + \bar{x}^2) \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_i^2 - 2\bar{x}\sum_{i=1}^n x_i + \sum_{i=1}^n \bar{x}^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_i^2 - 2\bar{x}(n\bar{x}) + n \bar{x}^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_i^2 - 2n\bar{x}^2 + n \bar{x}^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_i^2 - n\bar{x}^2
\end{align*}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})
  &amp;= \frac{1}{n-1} \sum_{i=1}^n (x_iy_i - \bar{x}y_i - \bar{y}x_i + \bar{x}\bar{y}) \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_iy_i - \bar{x} \sum_{i=1}^ny_i - \bar{y} \sum_{i=1}^n x_i + \sum_{i=1}^n \bar{x}\bar{y} \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_iy_i - n\bar{x} \bar{y} - n\bar{y} \bar{x} + n \bar{x}\bar{y} \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n x_iy_i - n\bar{x} \bar{y} \\
\end{align*}\]</span></p>
<p>then we can express <span class="math inline">\(\hat{\beta}_1\)</span> as:</p>
<p><span class="math display">\[\hat{\beta}_1 = \frac{(n-1)S_{xy}}{(n-1)S_{xx}^2}=\frac{S_{xy}}{S_{xx}^2} \]</span></p>
<p>Now notice that in order to find the Least Squares estimates you don’t require
the complete data set, but only require the following quantities:</p>
<ul>
<li><span class="math inline">\(\bar{y}\)</span>.</li>
<li><span class="math inline">\(\bar{x}\)</span>.</li>
<li><span class="math inline">\(S_{xx}^2\)</span>.</li>
<li><span class="math inline">\(S_{xy}\)</span>.</li>
</ul>
<div id="other-estimated-quantites" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Other estimated quantites<a href="simple-linear-regression.html#other-estimated-quantites" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we use the Least squares estimates in the regression equation, we can derive
other estimated quantities:</p>
<p>The estimated value for observation <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[ \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i \]</span></p>
<p>and the estimated error:</p>
<p><span class="math display">\[ \hat{e}_i = y_i - \hat{y}_i = y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i \]</span></p>
<p>And we can also compare our estimated regression line (blue) with the real
regression line (red) in the following as follows:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="simple-linear-regression.html#cb17-1" tabindex="-1"></a>outReg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Years <span class="sc">~</span> Glasses, <span class="at">data =</span> dat)</span>
<span id="cb17-2"><a href="simple-linear-regression.html#cb17-2" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> dat<span class="sc">$</span>Glasses,</span>
<span id="cb17-3"><a href="simple-linear-regression.html#cb17-3" tabindex="-1"></a>     <span class="at">y    =</span> dat<span class="sc">$</span>Years,</span>
<span id="cb17-4"><a href="simple-linear-regression.html#cb17-4" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Avg. Glasses of Wine per Week&quot;</span>,</span>
<span id="cb17-5"><a href="simple-linear-regression.html#cb17-5" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Life Expectancy (Years)&quot;</span>)</span>
<span id="cb17-6"><a href="simple-linear-regression.html#cb17-6" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> <span class="dv">75</span>,</span>
<span id="cb17-7"><a href="simple-linear-regression.html#cb17-7" tabindex="-1"></a>       <span class="at">b   =</span> <span class="fl">1.5</span>,</span>
<span id="cb17-8"><a href="simple-linear-regression.html#cb17-8" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb17-9"><a href="simple-linear-regression.html#cb17-9" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb17-10"><a href="simple-linear-regression.html#cb17-10" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outReg<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb17-11"><a href="simple-linear-regression.html#cb17-11" tabindex="-1"></a>       <span class="at">b   =</span> outReg<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb17-12"><a href="simple-linear-regression.html#cb17-12" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb17-13"><a href="simple-linear-regression.html#cb17-13" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/slr-real-vs-est-1.png" width="672" /></p>
</div>
</div>
<div id="properties-of-the-estimates" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Properties of the Estimates<a href="simple-linear-regression.html#properties-of-the-estimates" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The estimates <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> are linear combinations of
<span class="math inline">\(\mathbf{y} = (y_1,\ldots,y_n)&#39;\)</span>. To see this, notice the following:</p>
<p><span class="math display">\[\begin{align*}
\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) \\
  &amp;= \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} \\
  &amp;= \sum_{i=1}^n x_i y_i - \bar{x} \sum_{i=1}^n y_i \\
  &amp;= \sum_{i=1}^n x_i y_i - \sum_{i=1}^n \bar{x} y_i \\
  &amp;= \sum_{i=1}^n (x_i y_i - \bar{x} y_i) \\
  &amp;= \sum_{i=1}^n (x_i - \bar{x}) y_i \\
\end{align*}\]</span></p>
<p>Then</p>
<p><span class="math display">\[ \hat{\beta}_1 =  \frac{\sum_{i = 1}^n y_i x_i - n \bar{y} \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{\sum_{i=1}^n (x_i - \bar{x}) y_i}{\sum_{i=1}^n (x_i - \bar{x})^2} = \sum_{i=1}^n\frac{(x_i - \bar{x}) }{\sum_{i=1}^n (x_i - \bar{x})^2}y_i \]</span></p>
<p>and similarly:</p>
<p><span class="math display">\[ \hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} = \sum_{i=1}^n \frac{y_i}{n} - \sum_{i=1}^n\frac{(x_i - \bar{x}) }{\sum_{j = 1}^n x_j^2 - n \bar{x}^2}y_i \bar{x} = \sum_{i=1}^n \left( \frac{1}{n} - \frac{(x_i - \bar{x}) }{\sum_{j = 1}^n x_j^2 - n \bar{x}^2} \bar{x} \right)y_i \]</span></p>
<p>Also, notice that the sum of the errors is <span class="math inline">\(0\)</span>.</p>
<p><span class="math display">\[\begin{align*}
\sum_{i=1}^n \hat{e}_i
  &amp;= \sum_{i=1}^n(y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \\
  &amp;= \sum_{i=1}^n y_i - \sum_{i=1}^n \hat{\beta}_0 - \hat{\beta}_1 \sum_{i=1}^n x_i \\
  &amp;= n\bar{y} - n \hat{\beta}_0 - n \hat{\beta}_1 \bar{x} \\
  &amp;= n\bar{y} - n (\bar{y} - \hat{\beta}_1 \bar{x}) - n \hat{\beta}_1 \bar{x} \\
  &amp;= n\bar{y} - n \bar{y} + n \hat{\beta}_1 \bar{x} - n \hat{\beta}_1 \bar{x} \\
  &amp;= 0
\end{align*}\]</span></p>
<p>If we let <span class="math inline">\(\hat{\mathbf{e}} = (\hat{e}_i,\ldots,\hat{e}_n)&#39;\)</span> and <span class="math inline">\(\mathbf{x}=(x_1,\ldots,x_n)&#39;\)</span>,
two vectors of size <span class="math inline">\(n\)</span>, then we have that <span class="math inline">\(\hat{\mathbf{e}}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> are orthogonal.
That is:</p>
<p><span class="math display">\[\begin{align*}
\langle \hat{\mathbf{e}}, \mathbf{x}\rangle
  &amp;= \sum_{i=1}^{n} \hat{e}_i x_i \\
  &amp;= \sum_{i=1}^{n}  (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)x_i \\
  &amp;= \sum_{i=1}^{n}  (y_i x_i - \hat{\beta}_0x_i - \hat{\beta}_1 x_i x_i) \\
  &amp;= \sum_{i=1}^{n} y_i x_i - \sum_{i=1}^{n} \hat{\beta}_0x_i - \sum_{i=1}^{n} \hat{\beta}_1 x_i x_i \\
  &amp;= \sum_{i=1}^{n} y_i - n \hat{\beta}_0 \bar{x} - \hat{\beta}_1 \sum_{i=1}^{n} x_i^2 \\
  &amp;= \sum_{i=1}^{n} y_i - n (\bar{y} - \hat{\beta}_1 \bar{x}) \bar{x} - \hat{\beta}_1 \sum_{i=1}^{n} x_i^2 \\
  &amp;= \sum_{i=1}^{n} y_i - n \bar{y} \bar{x} + n\hat{\beta}_1 \bar{x}^2 - \hat{\beta}_1 \sum_{i=1}^{n} x_i^2 \\
  &amp;= \sum_{i=1}^{n} y_i - n \bar{y} \bar{x} - \hat{\beta}_1 (\sum_{i=1}^{n} x_i^2 - n\bar{x}^2)  \\
  &amp;= \sum_{i=1}^{n} y_i - n \bar{y} \bar{x} -  \frac{\sum_{i = 1}^n y_i x_i - n \bar{y} \bar{x}}{\sum_{i = 1}^n x_i^2 - n \bar{x}^2}(\sum_{i=1}^{n} x_i^2 - n\bar{x}^2)  \\
  &amp;= \sum_{i=1}^{n} y_i - n \bar{y} \bar{x} -  (\sum_{i = 1}^n y_i x_i - n \bar{y} \bar{x})  \\
  &amp;=0
\end{align*}\]</span></p>
<p>The same applies to <span class="math inline">\(\hat{\mathbf{y}}= (\hat{y}_1,\ldots,\hat{\mathbf{y}}_n)&#39;\)</span> and <span class="math inline">\(\hat{\mathbf{e}}\)</span>, as we can see:</p>
<p><span class="math display">\[\begin{align*}
\langle \hat{\mathbf{e}}, \hat{\mathbf{y}}\rangle
  &amp;= \sum_{i=1}^{n} \hat{e}_i \hat{y}_i \\
  &amp;= \sum_{i=1}^{n} \hat{e}_i(\hat{\beta}_0 + \hat{\beta}_1 x_i) \\
  &amp;= \sum_{i=1}^{n} (\hat{e}_i \hat{\beta}_0 + he_i \hat{\beta}_1 x_i) \\
  &amp;= \hat{\beta}_0 \sum_{i=1}^{n} \hat{e}_i + \hat{\beta}_1 \sum_{i=1}^{n} he_i x_i \\
  &amp;= \hat{\beta}_1 \langle \hat{\mathbf{e}}, \mathbf{x}\rangle  \\
  &amp;= 0
\end{align*}\]</span></p>
<p>Finally, the average of <span class="math inline">\(\hat{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are the same, to see this notice:</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n} \sum_{i=1}^n \hat{y}_i
  &amp;= \frac{1}{n} \sum_{i=1}^n (\hat{\beta}_0 + \hat{\beta}_1 x_i) \\
  &amp;= \frac{1}{n} (n \hat{\beta}_0 + \hat{\beta}_1 \sum_{i=1}^n x_i) \\
  &amp;= \frac{1}{n} (n \hat{\beta}_0 + n \hat{\beta}_1 \mathbf{x}) \\
  &amp;= \hat{\beta}_0 + \hat{\beta}_1 \mathbf{x}\\
  &amp;= \bar{y} - \hat{\beta}_1 \mathbf{x}+ \hat{\beta}_1 \mathbf{x}\\
  &amp;= \bar{y} \\
\end{align*}\]</span></p>
</div>
<div id="centering-and-standarizing-the-data" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Centering and Standarizing the Data<a href="simple-linear-regression.html#centering-and-standarizing-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Some transformations of the data can help the regression analysis
or make it more intuitive. There are 2 main transformations of the data:
<strong>centering</strong> and <strong>standardization</strong>.</p>
<p>Consider observations <span class="math inline">\(x_1,\ldots,x_n\)</span>, then the centered version of observation
<span class="math inline">\(i\)</span> is given by:</p>
<p><span class="math display">\[x_i&#39; = x_i - \bar{x}\]</span></p>
<p>The new observations <span class="math inline">\(x_1&#39;,\ldots,x_n&#39;\)</span> are centered and their mean is <span class="math inline">\(0\)</span>.</p>
<p><span class="math display">\[\bar{x}&#39; = \frac{1}{n} \sum_{i=1}^n x_i&#39; = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x}) = \frac{1}{n} \left(\sum_{i=1}^n x_i - \sum_{i=1}^n \bar{x} \right) = \frac{1}{n} \left(n\bar{x} - n \bar{x} \right) = 0\]</span>
Also, let us see that the variance of the standardized variables is the same as
the variance of the original observations.</p>
<p><span class="math display">\[ S_{xx}&#39; = \frac{1}{n-1} \sum_{i=1}^n (x_i&#39; - \bar{x}&#39;) = \frac{1}{n-1} \sum_{i=1}^n (x_i&#39;) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x}) = S_{xx} \]</span>
So the variance of the observations is not affected by the centering.</p>
<p>If we center another set of observations <span class="math inline">\(y_1,\ldots,y_n\)</span>, and compute the covariance,
we have that it also doesn’t change.</p>
<p><span class="math display">\[S_{xy}&#39; = \frac{1}{n-1} \sum_{i=1}^n (x_i&#39; - \bar{x})(y_i&#39; - \bar{x}) = \frac{1}{n-1} \sum_{i=1}^n (x_i&#39;)(y_i&#39;) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{x}) = S_{xy}\]</span></p>
<p>The standardized version of observation <span class="math inline">\(i\)</span> is given by:</p>
<p><span class="math display">\[x_i&#39;&#39; = \frac{x_i - \bar{x}}{\sqrt{S_{xx}}} = \frac{x_i&#39;}{\sqrt{S_{xx}}}\]</span></p>
<p>The standardized observations have mean of 0 and variance 1. Let’s see first that
the sample mean is</p>
<p><span class="math display">\[ \bar{x}_i&#39;&#39; =  \frac{1}{n} \sum_{i=1}^n x_i&#39;&#39; =  \frac{1}{n} \sum_{i=1}^n \frac{x_i&#39;}{\sqrt{S_{xx}}} = \frac{1}{\sqrt{S_{xx}}}\frac{1}{n} \sum_{i=1}^n x_i&#39; = \frac{1}{\sqrt{S_{xx}}} \bar{x}&#39; = 0\]</span></p>
<p>Now let us see that the variance of the standardized observations is 1.</p>
<p><span class="math display">\[\begin{align*}
S_{xx}&#39;&#39;
  &amp;= \frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; - \bar{x}&#39;&#39;)^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39;)^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n \left(\frac{x_i - \bar{x}}{\sqrt{S_{xx}}}\right)^2 \\
  &amp;= \frac{1}{n-1} \sum_{i=1}^n \frac{(x_i - \bar{x})^2}{S_{xx}} \\
  &amp;= \frac{1}{S_{xx}} \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2 \\
  &amp;= \frac{1}{S_{xx}}S_{xx} \\
  &amp;= 1
\end{align*}\]</span></p>
<p>Now, let us introduce the sample correlation as:</p>
<p><span class="math display">\[ r_{xy} = \frac{S_{xy}}{\sqrt{S_{xx}{S_{yy}}}} \]</span>
If we standardize two sets of observations, then the covaraince of the standardized version
is the correlation of the standardized version. Let us see it:</p>
<p><span class="math display">\[\begin{align*}
S_{xy}&#39;&#39;
  &amp;= \frac{1}{n-1} \sum_{i=1} (x_i&#39;&#39; - \bar{x}&#39;&#39;)(y_i&#39;&#39; - \bar{x}&#39;&#39;) \\
  &amp;= \frac{1}{n-1} \sum_{i=1} (x_i&#39;&#39;)(y_i&#39;&#39;) \\
  &amp;= \frac{1}{n-1} \sum_{i=1} \left(\frac{x_i - \bar{x}}{\sqrt{S_{xx}}}\right) \left(\frac{y_i - \bar{y}}{\sqrt{S_{yy}}}\right) \\
  &amp;= \frac{1}{\sqrt{S_{yy}}\sqrt{S_{xx}}}\frac{1}{n-1} \sum_{i=1} (x_i - \bar{x}) (y_i - \bar{y}) \\
  &amp;= \frac{1}{\sqrt{S_{yy}}\sqrt{S_{xx}}} S_{xy} \\
  &amp;= r_{xy}
\end{align*}\]</span></p>
<p>With this results, we can analyze the effects of following 3 scenarios on the
estimated coefficients:</p>
<ul>
<li>Independent variable centered.</li>
<li>Both, Independent and dependent variable centered.</li>
<li>Both, Independent and dependent variable standardized.</li>
</ul>
<div id="independent-variable-centered" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Independent variable centered<a href="simple-linear-regression.html#independent-variable-centered" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Lets compute the value for <span class="math inline">\(\beta_1\)</span> when the data is centered.</p>
<p><span class="math display">\[\hat{\beta}_1&#39; = \frac{S_{xy}&#39;}{S_{xx}&#39;} = \frac{S_{xy}}{S_{xx}} = \hat{\beta}_1 \]</span>
So centering the data doesn’t change the value of the estimated slope.</p>
<p><span class="math display">\[ \hat{\beta}_0&#39; = \bar{y} - \hat{\beta}_1&#39; \bar{x}&#39; = \bar{y} - \hat{\beta}_1&#39; 0 = \bar{y} \]</span>
So centering the data, makes the estimated intercept to coincide with the mean of
the independent variable.</p>
<p>We can see this in one of our example data sets, looking at the ad spending data
we can perform linear regression on the original data and the centered data:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="simple-linear-regression.html#cb18-1" tabindex="-1"></a><span class="co"># Read Data</span></span>
<span id="cb18-2"><a href="simple-linear-regression.html#cb18-2" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Ad spending Data.csv&quot;</span>)</span>
<span id="cb18-3"><a href="simple-linear-regression.html#cb18-3" tabindex="-1"></a><span class="co"># Assign data</span></span>
<span id="cb18-4"><a href="simple-linear-regression.html#cb18-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> dat<span class="sc">$</span>Ad.Spending</span>
<span id="cb18-5"><a href="simple-linear-regression.html#cb18-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> dat<span class="sc">$</span>Revenue</span>
<span id="cb18-6"><a href="simple-linear-regression.html#cb18-6" tabindex="-1"></a><span class="co"># Centers x</span></span>
<span id="cb18-7"><a href="simple-linear-regression.html#cb18-7" tabindex="-1"></a>xCen <span class="ot">&lt;-</span> x <span class="sc">-</span> <span class="fu">mean</span>(x)</span>
<span id="cb18-8"><a href="simple-linear-regression.html#cb18-8" tabindex="-1"></a><span class="co"># Linear regression on the original data</span></span>
<span id="cb18-9"><a href="simple-linear-regression.html#cb18-9" tabindex="-1"></a>outRegOri <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb18-10"><a href="simple-linear-regression.html#cb18-10" tabindex="-1"></a><span class="co"># Linear regression on the centered independent variable data</span></span>
<span id="cb18-11"><a href="simple-linear-regression.html#cb18-11" tabindex="-1"></a>outRegCen <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> xCen)</span>
<span id="cb18-12"><a href="simple-linear-regression.html#cb18-12" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb18-13"><a href="simple-linear-regression.html#cb18-13" tabindex="-1"></a><span class="do">## Two plots in the same image</span></span>
<span id="cb18-14"><a href="simple-linear-regression.html#cb18-14" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb18-15"><a href="simple-linear-regression.html#cb18-15" tabindex="-1"></a><span class="do">## Original data</span></span>
<span id="cb18-16"><a href="simple-linear-regression.html#cb18-16" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb18-17"><a href="simple-linear-regression.html#cb18-17" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb18-18"><a href="simple-linear-regression.html#cb18-18" tabindex="-1"></a>     <span class="at">y    =</span> y,</span>
<span id="cb18-19"><a href="simple-linear-regression.html#cb18-19" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb18-20"><a href="simple-linear-regression.html#cb18-20" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb18-21"><a href="simple-linear-regression.html#cb18-21" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb18-22"><a href="simple-linear-regression.html#cb18-22" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb18-23"><a href="simple-linear-regression.html#cb18-23" tabindex="-1"></a>       <span class="at">b   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb18-24"><a href="simple-linear-regression.html#cb18-24" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb18-25"><a href="simple-linear-regression.html#cb18-25" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb18-26"><a href="simple-linear-regression.html#cb18-26" tabindex="-1"></a><span class="do">## Independent Variable centered data</span></span>
<span id="cb18-27"><a href="simple-linear-regression.html#cb18-27" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb18-28"><a href="simple-linear-regression.html#cb18-28" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> xCen,</span>
<span id="cb18-29"><a href="simple-linear-regression.html#cb18-29" tabindex="-1"></a>     <span class="at">y    =</span> y,</span>
<span id="cb18-30"><a href="simple-linear-regression.html#cb18-30" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending (Centered)&quot;</span>,</span>
<span id="cb18-31"><a href="simple-linear-regression.html#cb18-31" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb18-32"><a href="simple-linear-regression.html#cb18-32" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb18-33"><a href="simple-linear-regression.html#cb18-33" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegCen<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb18-34"><a href="simple-linear-regression.html#cb18-34" tabindex="-1"></a>       <span class="at">b   =</span> outRegCen<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb18-35"><a href="simple-linear-regression.html#cb18-35" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb18-36"><a href="simple-linear-regression.html#cb18-36" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb18-37"><a href="simple-linear-regression.html#cb18-37" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v   =</span> <span class="dv">0</span>,</span>
<span id="cb18-38"><a href="simple-linear-regression.html#cb18-38" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/center-x-1.png" width="672" /></p>
<p>So we can appreciate that centering the independent variable just shifts the data
horizontally so the mean will be at zero.</p>
</div>
<div id="both-variables-centered" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Both Variables centered<a href="simple-linear-regression.html#both-variables-centered" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now lets see the effects when both variables are centered. Here, we will denote
the estimates again with one prime, that is <span class="math inline">\(\hat{\beta}&#39;\)</span>.</p>
<p>Again, the estimate of the slope doesn’t change:</p>
<p><span class="math display">\[\hat{\beta}_1&#39; = \frac{S_{xy}&#39;}{S_{xx}&#39;} = \frac{S_{xy}}{S_{xx}} = \hat{\beta}_1 \]</span>
while the estimate of the intercept becomes zero (the new mean of the centered
dependent variable)</p>
<p><span class="math display">\[ \hat{\beta}_0&#39; = \bar{y}&#39; - \hat{\beta}_1&#39; \bar{x}&#39; = \bar{y}&#39; = 0 \]</span>
The effect of this transformation can be observed, here:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="simple-linear-regression.html#cb19-1" tabindex="-1"></a><span class="co"># Read Data</span></span>
<span id="cb19-2"><a href="simple-linear-regression.html#cb19-2" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Ad spending Data.csv&quot;</span>)</span>
<span id="cb19-3"><a href="simple-linear-regression.html#cb19-3" tabindex="-1"></a><span class="co"># Assign data</span></span>
<span id="cb19-4"><a href="simple-linear-regression.html#cb19-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> dat<span class="sc">$</span>Ad.Spending</span>
<span id="cb19-5"><a href="simple-linear-regression.html#cb19-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> dat<span class="sc">$</span>Revenue</span>
<span id="cb19-6"><a href="simple-linear-regression.html#cb19-6" tabindex="-1"></a><span class="co"># Centers x and y</span></span>
<span id="cb19-7"><a href="simple-linear-regression.html#cb19-7" tabindex="-1"></a>xCen <span class="ot">&lt;-</span> x <span class="sc">-</span> <span class="fu">mean</span>(x)</span>
<span id="cb19-8"><a href="simple-linear-regression.html#cb19-8" tabindex="-1"></a>yCen <span class="ot">&lt;-</span> y <span class="sc">-</span> <span class="fu">mean</span>(y)</span>
<span id="cb19-9"><a href="simple-linear-regression.html#cb19-9" tabindex="-1"></a><span class="co"># Linear regression on the original data</span></span>
<span id="cb19-10"><a href="simple-linear-regression.html#cb19-10" tabindex="-1"></a>outRegOri <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb19-11"><a href="simple-linear-regression.html#cb19-11" tabindex="-1"></a><span class="co"># Linear regression on the centered data</span></span>
<span id="cb19-12"><a href="simple-linear-regression.html#cb19-12" tabindex="-1"></a>outRegCen <span class="ot">&lt;-</span> <span class="fu">lm</span>(yCen <span class="sc">~</span> xCen)</span>
<span id="cb19-13"><a href="simple-linear-regression.html#cb19-13" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb19-14"><a href="simple-linear-regression.html#cb19-14" tabindex="-1"></a><span class="do">## Two plots in the same image</span></span>
<span id="cb19-15"><a href="simple-linear-regression.html#cb19-15" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb19-16"><a href="simple-linear-regression.html#cb19-16" tabindex="-1"></a><span class="do">## Original data</span></span>
<span id="cb19-17"><a href="simple-linear-regression.html#cb19-17" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb19-18"><a href="simple-linear-regression.html#cb19-18" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb19-19"><a href="simple-linear-regression.html#cb19-19" tabindex="-1"></a>     <span class="at">y    =</span> y,</span>
<span id="cb19-20"><a href="simple-linear-regression.html#cb19-20" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb19-21"><a href="simple-linear-regression.html#cb19-21" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb19-22"><a href="simple-linear-regression.html#cb19-22" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb19-23"><a href="simple-linear-regression.html#cb19-23" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb19-24"><a href="simple-linear-regression.html#cb19-24" tabindex="-1"></a>       <span class="at">b   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb19-25"><a href="simple-linear-regression.html#cb19-25" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb19-26"><a href="simple-linear-regression.html#cb19-26" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb19-27"><a href="simple-linear-regression.html#cb19-27" tabindex="-1"></a><span class="do">## Centered data</span></span>
<span id="cb19-28"><a href="simple-linear-regression.html#cb19-28" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb19-29"><a href="simple-linear-regression.html#cb19-29" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> xCen,</span>
<span id="cb19-30"><a href="simple-linear-regression.html#cb19-30" tabindex="-1"></a>     <span class="at">y    =</span> yCen,</span>
<span id="cb19-31"><a href="simple-linear-regression.html#cb19-31" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending (Centered)&quot;</span>,</span>
<span id="cb19-32"><a href="simple-linear-regression.html#cb19-32" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb19-33"><a href="simple-linear-regression.html#cb19-33" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb19-34"><a href="simple-linear-regression.html#cb19-34" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegCen<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb19-35"><a href="simple-linear-regression.html#cb19-35" tabindex="-1"></a>       <span class="at">b   =</span> outRegCen<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb19-36"><a href="simple-linear-regression.html#cb19-36" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb19-37"><a href="simple-linear-regression.html#cb19-37" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb19-38"><a href="simple-linear-regression.html#cb19-38" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v   =</span> <span class="dv">0</span>,</span>
<span id="cb19-39"><a href="simple-linear-regression.html#cb19-39" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb19-40"><a href="simple-linear-regression.html#cb19-40" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h   =</span> <span class="dv">0</span>,</span>
<span id="cb19-41"><a href="simple-linear-regression.html#cb19-41" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/center-xy-1.png" width="672" /></p>
</div>
<div id="independent-and-dependent-variable-standardized" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Independent and dependent variable standardized<a href="simple-linear-regression.html#independent-and-dependent-variable-standardized" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Again we start we the slope estimate:</p>
<p><span class="math display">\[\hat{\beta}_1&#39;&#39; = \frac{S_{xy}&#39;&#39;}{S_{xx}&#39;&#39;} = \frac{r_{xy}}{1} =r_{xy} \]</span>
so, the estimate of the slope is the sample correlation of the original observations.</p>
<p>Again, we can see this graphically:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="simple-linear-regression.html#cb20-1" tabindex="-1"></a><span class="co"># Read Data</span></span>
<span id="cb20-2"><a href="simple-linear-regression.html#cb20-2" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Ad spending Data.csv&quot;</span>)</span>
<span id="cb20-3"><a href="simple-linear-regression.html#cb20-3" tabindex="-1"></a><span class="co"># Assign data</span></span>
<span id="cb20-4"><a href="simple-linear-regression.html#cb20-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> dat<span class="sc">$</span>Ad.Spending</span>
<span id="cb20-5"><a href="simple-linear-regression.html#cb20-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> dat<span class="sc">$</span>Revenue</span>
<span id="cb20-6"><a href="simple-linear-regression.html#cb20-6" tabindex="-1"></a><span class="co"># Standardizes x and y</span></span>
<span id="cb20-7"><a href="simple-linear-regression.html#cb20-7" tabindex="-1"></a>xSta <span class="ot">&lt;-</span> (x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">var</span>(x))</span>
<span id="cb20-8"><a href="simple-linear-regression.html#cb20-8" tabindex="-1"></a>ySta <span class="ot">&lt;-</span> (y <span class="sc">-</span> <span class="fu">mean</span>(y))<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">var</span>(y))</span>
<span id="cb20-9"><a href="simple-linear-regression.html#cb20-9" tabindex="-1"></a><span class="co"># Linear regression on the original data</span></span>
<span id="cb20-10"><a href="simple-linear-regression.html#cb20-10" tabindex="-1"></a>outRegOri <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb20-11"><a href="simple-linear-regression.html#cb20-11" tabindex="-1"></a><span class="co"># Linear regression on the standard data</span></span>
<span id="cb20-12"><a href="simple-linear-regression.html#cb20-12" tabindex="-1"></a>outRegSta <span class="ot">&lt;-</span> <span class="fu">lm</span>(ySta <span class="sc">~</span> xSta)</span>
<span id="cb20-13"><a href="simple-linear-regression.html#cb20-13" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb20-14"><a href="simple-linear-regression.html#cb20-14" tabindex="-1"></a><span class="do">## Two plots in the same image</span></span>
<span id="cb20-15"><a href="simple-linear-regression.html#cb20-15" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb20-16"><a href="simple-linear-regression.html#cb20-16" tabindex="-1"></a><span class="do">## Original data</span></span>
<span id="cb20-17"><a href="simple-linear-regression.html#cb20-17" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb20-18"><a href="simple-linear-regression.html#cb20-18" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb20-19"><a href="simple-linear-regression.html#cb20-19" tabindex="-1"></a>     <span class="at">y    =</span> y,</span>
<span id="cb20-20"><a href="simple-linear-regression.html#cb20-20" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb20-21"><a href="simple-linear-regression.html#cb20-21" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb20-22"><a href="simple-linear-regression.html#cb20-22" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb20-23"><a href="simple-linear-regression.html#cb20-23" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb20-24"><a href="simple-linear-regression.html#cb20-24" tabindex="-1"></a>       <span class="at">b   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb20-25"><a href="simple-linear-regression.html#cb20-25" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb20-26"><a href="simple-linear-regression.html#cb20-26" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb20-27"><a href="simple-linear-regression.html#cb20-27" tabindex="-1"></a><span class="do">## Standard data</span></span>
<span id="cb20-28"><a href="simple-linear-regression.html#cb20-28" tabindex="-1"></a><span class="co"># Plots the points</span></span>
<span id="cb20-29"><a href="simple-linear-regression.html#cb20-29" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> xSta,</span>
<span id="cb20-30"><a href="simple-linear-regression.html#cb20-30" tabindex="-1"></a>     <span class="at">y    =</span> ySta,</span>
<span id="cb20-31"><a href="simple-linear-regression.html#cb20-31" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending (Centered)&quot;</span>,</span>
<span id="cb20-32"><a href="simple-linear-regression.html#cb20-32" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>)</span>
<span id="cb20-33"><a href="simple-linear-regression.html#cb20-33" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb20-34"><a href="simple-linear-regression.html#cb20-34" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegSta<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb20-35"><a href="simple-linear-regression.html#cb20-35" tabindex="-1"></a>       <span class="at">b   =</span> outRegSta<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb20-36"><a href="simple-linear-regression.html#cb20-36" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb20-37"><a href="simple-linear-regression.html#cb20-37" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb20-38"><a href="simple-linear-regression.html#cb20-38" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v   =</span> <span class="dv">0</span>,</span>
<span id="cb20-39"><a href="simple-linear-regression.html#cb20-39" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb20-40"><a href="simple-linear-regression.html#cb20-40" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h   =</span> <span class="dv">0</span>,</span>
<span id="cb20-41"><a href="simple-linear-regression.html#cb20-41" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/slr-standarize-xy-1.png" width="672" /></p>
<p>Now, let us see that the correlation is always in the interval <span class="math inline">\((-1,1)\)</span>. To see
this, notice the following:</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; + y_i&#39;&#39;)^2
  &amp;= \frac{1}{n-1} \sum_{i=1}^n \left((x_i&#39;&#39;)^2 + 2x_i&#39;&#39; y_i&#39;&#39; + (y_i&#39;&#39;)^2 \right) \\
  &amp;= \frac{\sum_{i=1}^n (x_i&#39;&#39;)^2}{n-1}  + 2\frac{\sum_{i=1}^n x_i&#39;&#39;y_i&#39;&#39;}{n-1}  + \frac{\sum_{i=1}^n (y_i&#39;&#39;)^2}{n-1} \\
  &amp;= \frac{\sum_{i=1}^n (x_i&#39;&#39; - \bar{x}&#39;&#39;)^2}{n-1}  + 2\frac{\sum_{i=1}^n (x_i&#39;&#39; - \bar{x}&#39;&#39;)(y_i&#39;&#39; - \bar{y}&#39;&#39;)}{n-1}  + \frac{\sum_{i=1}^n (y_i&#39;&#39; - \bar{y}&#39;&#39;)^2}{n-1} \\
  &amp;= S_{xx}&#39;&#39; + 2 S_{xy}&#39;&#39; + S_{yy}&#39;&#39; \\
  &amp;= 1 + 2r_{xy} + 1 \\
  &amp;= 2(1 + r_{xy})
\end{align*}\]</span></p>
<p>In a similar way it can be shown that:</p>
<p><span class="math display">\[\frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; + y_i&#39;&#39;)^2 = 2(1 - r_{xy})\]</span></p>
<p>Now since, <span class="math display">\[\frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; + y_i&#39;&#39;)^2 \geq 0\]</span>
then we have that</p>
<p><span class="math display">\[\begin{align*}
\frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; + y_i&#39;&#39;)^2 \geq 0
  &amp;\implies 2(1 + r_{xy}) \geq 0 \\
  &amp;\implies 1 + r_{xy} \geq 0 \\
  &amp;\implies r_{xy} \geq -1 \\
\end{align*}\]</span></p>
<p>Similarly, since</p>
<p><span class="math display">\[\frac{1}{n-1} \sum_{i=1}^n (x_i&#39;&#39; - y_i&#39;&#39;)^2 \geq 0\]</span></p>
<p>implies</p>
<p><span class="math display">\[r_{xy} \leq 1 \]</span>
then, we have that:
<span class="math display">\[ -1 \leq r_{xy} \leq 1\]</span>
which implies that the slope of the regression analysis after standarizing both
variables is going to be in the interval <span class="math inline">\((-1, 1)\)</span>.</p>
</div>
</div>
<div id="coefficient-of-determination" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Coefficient of Determination<a href="simple-linear-regression.html#coefficient-of-determination" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far, we have been concerned on findin the “best” line, that is estimating the
coefficients that minimize the sum of squared errors. We have find some derivated
estimated values and some properties of these values. However, we hanven’t analized
how good is our estimation. To see how well we are doing we will look at the
coeficient of determination. To do so we will first introduce some quantities:</p>
<p><strong>Total Sum of Squares</strong></p>
<p><span class="math display">\[SS_{tot} = \sum_{i=1}^n (y_i - \bar{y})\]</span></p>
<p>Is a measure of total variability of the dependent
variable. You can think of it in many ways:</p>
<ul>
<li>As a proxy for uncertainty. The bigger the more uncertainty in the dependent
varaible.</li>
<li>It is proportional to the sample varaince.</li>
<li>It is what you get if when you solve the following minimization problem:</li>
</ul>
<p><span class="math display">\[ \min_{a} \sum_{i=1}^n (y_i - \beta_0)^2 \]</span>
that is, the best you can do to minimize the sum of squares without having access
to the independent variables <span class="math inline">\(x_1,\ldots,x_n\)</span>.</p>
<p><strong>Residual Sum of Squares</strong></p>
<p><span class="math display">\[ SS_{res} = \sum_{i=1}^n(\hat{e}_i)^2 = \sum_{i=1}^n(y_i - \hat{y}_i)^2\]</span></p>
<p>The residual Sum of Squares is the minimum value of our optimization problem. It
is the the amount of variability that no matter what we do we will have remaing
even after finding the “best” line.</p>
<p><strong>Explained Sum of Squares</strong></p>
<p><span class="math display">\[ SS_{reg} = \sum_{i=1}^n(\hat{y}_i - \bar{y}) = \sum_{i=1}^n(\hat{y}_i - \hat{\bar{y}}) \]</span></p>
<p>The variability of the fitted value. This is the variability we can explain with
our regression model.</p>
<p>These 3 quantities are related by:</p>
<p><span class="math display">\[ SS_{tot} = SS_{reg} + SS_{res} \]</span>
That is the total variability si the sum of the variability that is explained by
the regression model and the variability we can’t explain with the regression model.</p>
<p><span class="math display">\[\begin{align*}
SS_{tot}
  &amp;= \sum_{i=1}^n(y_i - \bar{y})^2 = \sum_{i=1}^n(y_i - \hat{y}_i + \hat{y}_i - \bar{y})^2 \\
  &amp;= \sum_{i=1}^n\left((y_i - \hat{y}_i)^2 + 2(y_i - \hat{y}_i)(\hat{y}_i - \bar{y}) + (\hat{y}_i - \bar{y})^2\right) \\
  &amp;= \sum_{i=1}^n(y_i - \hat{y}_i)^2 + 2 \sum_{i=1}^n(y_i - \hat{y}_i)(\hat{y}_i - \bar{y}) + \sum_{i=1}^n(\hat{y}_i - \bar{y})^2 \\
  &amp;= SS_{res} + 2 \sum_{i=1}^n(y_i - \hat{y}_i)(\hat{y}_i - \bar{y}) + SS_{reg} \\
  &amp;= SS_{res} + 2 \sum_{i=1}^n\hat{e}_i(\hat{y}_i - \bar{y}) + SS_{reg} \\
  &amp;= SS_{res} + 2 \sum_{i=1}^n(\hat{e}_i\hat{y}_i - \hat{e}_i\bar{y}) + SS_{reg} \\
  &amp;= SS_{res} + 2 \sum_{i=1}^n\hat{e}_i\hat{y}_i - 2 \sum_{i=1}^n\hat{e}_i\bar{y} + SS_{reg} \\
  &amp;= SS_{res} + 2(0) - 2  \bar{y} \sum_{i=1}^n\hat{e}_i + SS_{reg} \\
  &amp;= SS_{res} - 2 \bar{y} (0) + SS_{reg} \\
  &amp;= SS_{res} + SS_{reg} \\
\end{align*}\]</span></p>
<p><strong>Coefficient of Determination</strong></p>
<p><span class="math display">\[ R^2 = \frac{SS_{reg}}{SS_{tot}} = 1 - \frac{SS_{res}}{SS_{tot}} \]</span>
The coefficient of determination then can be explained as the percentage of the
total varaibility that can be explained with linear regression.</p>
<p>As a percentage, it has to be a number between 0 and 1. To see this let us show
that:</p>
<p><span class="math display">\[ R^2 = r_{xy}^2 \]</span>
To see this, first let us express <span class="math inline">\(SS_{reg}\)</span> in a more convinient way:</p>
<p><span class="math display">\[\begin{align*}
SS_{reg}
  &amp;= \sum_{i=1}^n(\hat{y}_i - \bar{y})^2 \\
  &amp;= \sum_{i=1}^n(\hat{\beta}_0 + \hat{\beta}_1 x_i - \bar{y})^2 \\
  &amp;= \sum_{i=1}^n(\bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 x_i - \bar{y})^2 \\
  &amp;= \sum_{i=1}^n(\hat{\beta}_1 x_i - \hat{\beta}_1 \bar{x})^2 \\
  &amp;= \sum_{i=1}^n\hat{\beta}_1^2(x_i - \bar{x})^2 \\
  &amp;= \hat{\beta}_1^2 \sum_{i=1}^n(x_i - \bar{x})^2 \\
  &amp;= \hat{\beta}_1^2 S_{xx} (n-1) \\
  &amp;= \left( \frac{S_{xy}}{S_{xx}} \right)^2 S_{xx} (n-1) \\
  &amp;= \frac{S_{xy}^2}{S_{xx}^2} S_{xx} (n-1) \\
  &amp;= \frac{S_{xy}^2}{S_{xx}} (n-1) \\
\end{align*}\]</span></p>
<p>Then, we can see that:</p>
<p><span class="math display">\[\begin{align*}
R^2
  &amp;= \frac{SS_{reg}}{SS_{tot}} \\
  &amp;= \frac{\frac{S_{xy}^2}{S_{xx}} (n-1)}{\sum_{i=1}^n(y_i - \bar{y})^2} \\
  &amp;= \frac{\frac{S_{xy}^2}{S_{xx}} (n-1)}{S_{yy}(n-1)} \\
  &amp;= \frac{S_{xy}^2}{S_{xx}S_{yy}} \\
  &amp;= \left( \frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}} \right)^2 \\
  &amp;= r_{xy}^2
\end{align*}\]</span></p>
<p>The bigger the <span class="math inline">\(R^2\)</span>, the better is the fit of our linear model. The <span class="math inline">\(R^2\)</span> can
be low for 2 reasons:</p>
<ul>
<li>The first one is if our data is not linear, then a linear
model will explain little about the relationship (some times a linear model can
be a good approximation of a non-linear model).</li>
<li>The second reason, is when the
data is noisy. This can reduce the <span class="math inline">\(R^2\)</span> even when we know the relationship
between the variables is linear.</li>
</ul>
<p>As an example of noisy data, recall the Ad spending data. I actually generated
the data under a linear model, so the relationship between the variables is linear.
You can verify this be looking at the code where the data is generated in the introduction.
Next I show the effects of adding additional noise to the data, at 3 levels:</p>
<ul>
<li>Level1: Small Noise.</li>
<li>Level2: Medium Noise.</li>
<li>Level3: High noise.</li>
</ul>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="simple-linear-regression.html#cb21-1" tabindex="-1"></a><span class="co"># Read Data</span></span>
<span id="cb21-2"><a href="simple-linear-regression.html#cb21-2" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Ad spending Data.csv&quot;</span>)</span>
<span id="cb21-3"><a href="simple-linear-regression.html#cb21-3" tabindex="-1"></a><span class="co"># Assign data</span></span>
<span id="cb21-4"><a href="simple-linear-regression.html#cb21-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> dat<span class="sc">$</span>Ad.Spending</span>
<span id="cb21-5"><a href="simple-linear-regression.html#cb21-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> dat<span class="sc">$</span>Revenue</span>
<span id="cb21-6"><a href="simple-linear-regression.html#cb21-6" tabindex="-1"></a></span>
<span id="cb21-7"><a href="simple-linear-regression.html#cb21-7" tabindex="-1"></a><span class="co"># Adds Noise</span></span>
<span id="cb21-8"><a href="simple-linear-regression.html#cb21-8" tabindex="-1"></a>yNoiLe1 <span class="ot">&lt;-</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">sd =</span>  <span class="dv">50</span>)</span>
<span id="cb21-9"><a href="simple-linear-regression.html#cb21-9" tabindex="-1"></a>yNoiLe2 <span class="ot">&lt;-</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">sd =</span> <span class="dv">200</span>)</span>
<span id="cb21-10"><a href="simple-linear-regression.html#cb21-10" tabindex="-1"></a>yNoiLe3 <span class="ot">&lt;-</span> y <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">sd =</span> <span class="dv">500</span>)</span>
<span id="cb21-11"><a href="simple-linear-regression.html#cb21-11" tabindex="-1"></a></span>
<span id="cb21-12"><a href="simple-linear-regression.html#cb21-12" tabindex="-1"></a><span class="co"># Auxiliary Variables</span></span>
<span id="cb21-13"><a href="simple-linear-regression.html#cb21-13" tabindex="-1"></a>ymax <span class="ot">&lt;-</span> <span class="fu">max</span>(y, yNoiLe1, yNoiLe2, yNoiLe3)</span>
<span id="cb21-14"><a href="simple-linear-regression.html#cb21-14" tabindex="-1"></a>ymin <span class="ot">&lt;-</span> <span class="fu">min</span>(y, yNoiLe1, yNoiLe2, yNoiLe3)</span>
<span id="cb21-15"><a href="simple-linear-regression.html#cb21-15" tabindex="-1"></a>xmax <span class="ot">=</span> <span class="fu">max</span>(x)</span>
<span id="cb21-16"><a href="simple-linear-regression.html#cb21-16" tabindex="-1"></a>xmin <span class="ot">=</span> <span class="fu">min</span>(x)</span>
<span id="cb21-17"><a href="simple-linear-regression.html#cb21-17" tabindex="-1"></a></span>
<span id="cb21-18"><a href="simple-linear-regression.html#cb21-18" tabindex="-1"></a><span class="co"># Performs Linear Regression</span></span>
<span id="cb21-19"><a href="simple-linear-regression.html#cb21-19" tabindex="-1"></a>outRegOri    <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x)</span>
<span id="cb21-20"><a href="simple-linear-regression.html#cb21-20" tabindex="-1"></a>outRegNoiLe1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(yNoiLe1 <span class="sc">~</span> x)</span>
<span id="cb21-21"><a href="simple-linear-regression.html#cb21-21" tabindex="-1"></a>outRegNoiLe2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(yNoiLe2 <span class="sc">~</span> x)</span>
<span id="cb21-22"><a href="simple-linear-regression.html#cb21-22" tabindex="-1"></a>outRegNoiLe3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(yNoiLe3 <span class="sc">~</span> x)</span>
<span id="cb21-23"><a href="simple-linear-regression.html#cb21-23" tabindex="-1"></a></span>
<span id="cb21-24"><a href="simple-linear-regression.html#cb21-24" tabindex="-1"></a><span class="co"># Plots</span></span>
<span id="cb21-25"><a href="simple-linear-regression.html#cb21-25" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb21-26"><a href="simple-linear-regression.html#cb21-26" tabindex="-1"></a></span>
<span id="cb21-27"><a href="simple-linear-regression.html#cb21-27" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb21-28"><a href="simple-linear-regression.html#cb21-28" tabindex="-1"></a>     <span class="at">y    =</span> y,</span>
<span id="cb21-29"><a href="simple-linear-regression.html#cb21-29" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb21-30"><a href="simple-linear-regression.html#cb21-30" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>,</span>
<span id="cb21-31"><a href="simple-linear-regression.html#cb21-31" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Original Data&quot;</span>,</span>
<span id="cb21-32"><a href="simple-linear-regression.html#cb21-32" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),</span>
<span id="cb21-33"><a href="simple-linear-regression.html#cb21-33" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax))</span>
<span id="cb21-34"><a href="simple-linear-regression.html#cb21-34" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb21-35"><a href="simple-linear-regression.html#cb21-35" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb21-36"><a href="simple-linear-regression.html#cb21-36" tabindex="-1"></a>       <span class="at">b   =</span> outRegOri<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb21-37"><a href="simple-linear-regression.html#cb21-37" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb21-38"><a href="simple-linear-regression.html#cb21-38" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb21-39"><a href="simple-linear-regression.html#cb21-39" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb21-40"><a href="simple-linear-regression.html#cb21-40" tabindex="-1"></a>     <span class="at">y    =</span> yNoiLe1,</span>
<span id="cb21-41"><a href="simple-linear-regression.html#cb21-41" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb21-42"><a href="simple-linear-regression.html#cb21-42" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>,</span>
<span id="cb21-43"><a href="simple-linear-regression.html#cb21-43" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Small Noise Added&quot;</span>,</span>
<span id="cb21-44"><a href="simple-linear-regression.html#cb21-44" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),</span>
<span id="cb21-45"><a href="simple-linear-regression.html#cb21-45" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax))</span>
<span id="cb21-46"><a href="simple-linear-regression.html#cb21-46" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb21-47"><a href="simple-linear-regression.html#cb21-47" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegNoiLe1<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb21-48"><a href="simple-linear-regression.html#cb21-48" tabindex="-1"></a>       <span class="at">b   =</span> outRegNoiLe1<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb21-49"><a href="simple-linear-regression.html#cb21-49" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb21-50"><a href="simple-linear-regression.html#cb21-50" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb21-51"><a href="simple-linear-regression.html#cb21-51" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb21-52"><a href="simple-linear-regression.html#cb21-52" tabindex="-1"></a>     <span class="at">y    =</span> yNoiLe2,</span>
<span id="cb21-53"><a href="simple-linear-regression.html#cb21-53" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb21-54"><a href="simple-linear-regression.html#cb21-54" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>,</span>
<span id="cb21-55"><a href="simple-linear-regression.html#cb21-55" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Medium Noise Added&quot;</span>,</span>
<span id="cb21-56"><a href="simple-linear-regression.html#cb21-56" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),</span>
<span id="cb21-57"><a href="simple-linear-regression.html#cb21-57" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax))</span>
<span id="cb21-58"><a href="simple-linear-regression.html#cb21-58" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb21-59"><a href="simple-linear-regression.html#cb21-59" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegNoiLe2<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb21-60"><a href="simple-linear-regression.html#cb21-60" tabindex="-1"></a>       <span class="at">b   =</span> outRegNoiLe2<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb21-61"><a href="simple-linear-regression.html#cb21-61" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb21-62"><a href="simple-linear-regression.html#cb21-62" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb21-63"><a href="simple-linear-regression.html#cb21-63" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x    =</span> x,</span>
<span id="cb21-64"><a href="simple-linear-regression.html#cb21-64" tabindex="-1"></a>     <span class="at">y    =</span> yNoiLe3,</span>
<span id="cb21-65"><a href="simple-linear-regression.html#cb21-65" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Ad spending&quot;</span>,</span>
<span id="cb21-66"><a href="simple-linear-regression.html#cb21-66" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Revenue&quot;</span>,</span>
<span id="cb21-67"><a href="simple-linear-regression.html#cb21-67" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;High Noise Added&quot;</span>,</span>
<span id="cb21-68"><a href="simple-linear-regression.html#cb21-68" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),</span>
<span id="cb21-69"><a href="simple-linear-regression.html#cb21-69" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax))</span>
<span id="cb21-70"><a href="simple-linear-regression.html#cb21-70" tabindex="-1"></a><span class="co"># Plots the regression line</span></span>
<span id="cb21-71"><a href="simple-linear-regression.html#cb21-71" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a   =</span> outRegNoiLe3<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb21-72"><a href="simple-linear-regression.html#cb21-72" tabindex="-1"></a>       <span class="at">b   =</span> outRegNoiLe3<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb21-73"><a href="simple-linear-regression.html#cb21-73" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb21-74"><a href="simple-linear-regression.html#cb21-74" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/r2-noise-1.png" width="672" /></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="simple-linear-regression.html#cb22-1" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Original Data LM summary&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Original Data LM summary&quot;</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="simple-linear-regression.html#cb24-1" tabindex="-1"></a><span class="fu">summary</span>(outRegOri)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -248.394  -58.805    3.782   63.577  196.745 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 997.3894    28.8185   34.61   &lt;2e-16 ***
## x             5.0247     0.3818   13.16   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 89.01 on 98 degrees of freedom
## Multiple R-squared:  0.6386, Adjusted R-squared:  0.6349 
## F-statistic: 173.2 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="simple-linear-regression.html#cb26-1" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Level 1 LM summary&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Level 1 LM summary&quot;</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="simple-linear-regression.html#cb28-1" tabindex="-1"></a><span class="fu">summary</span>(outRegNoiLe1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = yNoiLe1 ~ x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -225.09  -62.78  -11.97   73.73  254.06 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1004.0513    30.9057   32.49   &lt;2e-16 ***
## x              4.9766     0.4095   12.15   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 95.45 on 98 degrees of freedom
## Multiple R-squared:  0.6011, Adjusted R-squared:  0.5971 
## F-statistic: 147.7 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="simple-linear-regression.html#cb30-1" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Level 2 LM summary&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Level 2 LM summary&quot;</code></pre>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="simple-linear-regression.html#cb32-1" tabindex="-1"></a><span class="fu">summary</span>(outRegNoiLe2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = yNoiLe2 ~ x)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -588.4 -122.2    8.4  136.1  449.7 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1007.1088    64.7010  15.566  &lt; 2e-16 ***
## x              4.9009     0.8573   5.717 1.17e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 199.8 on 98 degrees of freedom
## Multiple R-squared:  0.2501, Adjusted R-squared:  0.2424 
## F-statistic: 32.68 on 1 and 98 DF,  p-value: 1.173e-07</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="simple-linear-regression.html#cb34-1" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Level 3 LM summary&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Level 3 LM summary&quot;</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="simple-linear-regression.html#cb36-1" tabindex="-1"></a><span class="fu">summary</span>(outRegNoiLe3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = yNoiLe3 ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1157.74  -264.68   -27.29   239.51   894.85 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  998.139    134.510   7.421 4.28e-11 ***
## x              4.948      1.782   2.776  0.00659 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 415.4 on 98 degrees of freedom
## Multiple R-squared:  0.0729, Adjusted R-squared:  0.06344 
## F-statistic: 7.706 on 1 and 98 DF,  p-value: 0.006592</code></pre>
<p>where we observe that the point cloud is more dispersed and looks less than a line
the more noise is added, but the estimated regression line changes only by a little.
We can also see how the <span class="math inline">\(R^2\)</span> becomes smaller as more noise is added.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
