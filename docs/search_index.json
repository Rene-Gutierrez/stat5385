[["index.html", "1 Stat 5385/6385", " 1 Stat 5385/6385 This is the website for STAT5385. It will contain the relevant information for the course and lecture notes and code seen in class. Find the syllabus here: Syllabus "],["prerequisites.html", "2 Prerequisites 2.1 General Math 2.2 Linear Algebra 2.3 Probability 2.4 Statistics 2.5 Calculus", " 2 Prerequisites Before diving into the course, it’s important to have a solid understanding of the following foundational concepts. These are categorized into five key topics: General Math Linear Algebra Probability Statistics Calculus 2.1 General Math You should be familiar with the summation operator \\(\\sum\\). This operator is defined as follows: \\[\\sum_{i=1}^n x_i = x_1 + x_2 + \\ldots + x_n \\] Key properties of the summation operator include: Linearity: \\[\\sum_{i=1}^N (a + b x_i) = aN + b \\sum_{i=1}^N x_i\\] Additivity: \\[\\sum_{i=1}^N (x_i + y_i) = \\sum_{i=1}^N x_i + \\sum_{i=1}^N y_i\\] 2.2 Linear Algebra You should be familiar with the following linear algebra concepts: Matrices Determinants Eigenvalues and Eigenvectors Diagonalization Vector Spaces Linear Transformations 2.3 Probability Key probability concepts to understand include: Expected Value Variance Covariance Correlation Joint, Marginal, and Conditional Distributions Independence Central Limit Theorem Distributions: Normal Chi-Squared (\\(\\chi^2\\)) t-distribution F-distribution 2.4 Statistics Essential statistical concepts include: Point Estimation: Maximum Likelihood Least Squares Estimation Properties of Point Estimators: Unbiased Consistent Minimum Variance Interval Estimation Hypothesis Testing 2.5 Calculus Key calculus topics include: Gradients Optimization "],["introduction.html", "3 Introduction 3.1 Examples", " 3 Introduction Linear regression is a statistical method used to analyze the relationship between at least two variables: one dependent variable and at least one independent variable. This technique is closely tied to the correlation coefficient, which measures the strength and direction of a linear relationship between variables. In this document, we will explore how these concepts are connected. Linear regression is typically applied for three main purposes: Description: To describe the relationship between the variables under analysis. Control: To predict how changes in the independent variables will affect the dependent variable. Prediction: To forecast the value of the dependent variable based on new observations of the independent variables. 3.1 Examples 3.1.1 Ad Spending Imagine you are a newly hired data scientist at a mattress company. Your manager asks you to analyze the relationship between Google ad spending and mattress sales revenue. To illustrate this scenario, I have simulated a dataset: # Ad Spending Example # Set Seed set.seed(8272024) # Data Simulation x &lt;- rnorm(n = 100, mean = 70, sd = 30) y &lt;- 1000 + 5 * x + rnorm(n = 100, mean = 0, sd = 100) # Creates the Data Frame datAd &lt;- data.frame(cbind(y,x)) # Names the Variables colnames(datAd) &lt;- c(&quot;Revenue&quot;, &quot;Ad Spending&quot;) # Saves to csv write.csv(x = datAd[, c(1, 2)], file = &quot;Ad spending Data.csv&quot;, row.names = FALSE) You can load the dataset as follows: dat &lt;- read.csv(file = &quot;Ad spending Data.csv&quot;) To visualize the data: plot(x = dat$Ad.Spending, y = dat$Revenue, xlab = &quot;Ad Spending ($)&quot;, ylab = &quot;Revenue ($)&quot;) Next, you can perform a linear regression analysis: outReg &lt;- lm(Revenue ~ Ad.Spending, data = dat) The most important results from the regression analysis can be summarized as follows: summary(outReg) ## ## Call: ## lm(formula = Revenue ~ Ad.Spending, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -248.394 -58.805 3.782 63.577 196.745 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 997.3894 28.8185 34.61 &lt;2e-16 *** ## Ad.Spending 5.0247 0.3818 13.16 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 89.01 on 98 degrees of freedom ## Multiple R-squared: 0.6386, Adjusted R-squared: 0.6349 ## F-statistic: 173.2 on 1 and 98 DF, p-value: &lt; 2.2e-16 For now, let’s focus on the estimate for the intercept and the Ad.Spending coefficient. The intercept indicates the expected revenue when ad spending is zero. Based on your analysis, you observe that even without an ad campaign, mattress sales generate \\(r outReg\\)coefficients[1]. The coefficient for Ad.Spending shows that each dollar spent on ads increases revenue by \\(r outReg\\)coefficients[2]. To visualize the regression line: plot(x = dat$Ad.Spending, y = dat$Revenue, xlab = &quot;Ad Spending ($)&quot;, ylab = &quot;Revenue ($)&quot;) abline(a = outReg$coefficients[1], b = outReg$coefficients[2], col = &#39;red&#39;, lwd = 2) The red regression line represents the “best fit” for these variables. In this context, “best fit” means the line that minimizes the sum of the squared distances from each point to the line. For comparison, here are examples of other lines that do not fit as well: Different slope (coefficient for the Ad.Spending variable): plot(x = dat$Ad.Spending, y = dat$Revenue, xlab = &quot;Ad Spending ($)&quot;, ylab = &quot;Revenue ($)&quot;) abline(a = outReg$coefficients[1], b = outReg$coefficients[2], col = &#39;red&#39;, lwd = 2) abline(a = outReg$coefficients[1], b = 6, col = &#39;blue&#39;, lwd = 2) Different intercept: plot(x = dat$Ad.Spending, y = dat$Revenue, xlab = &quot;Ad Spending ($)&quot;, ylab = &quot;Revenue ($)&quot;) abline(a = outReg$coefficients[1], b = outReg$coefficients[2], col = &#39;red&#39;, lwd = 2) abline(a = 1100, b = outReg$coefficients[2], col = &#39;blue&#39;, lwd = 2) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
